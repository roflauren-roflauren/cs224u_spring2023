{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf85bea0-68bf-4405-96ec-37579b2e9587",
   "metadata": {},
   "source": [
    "# Homework and bakeoff: Few-shot OpenQA with DSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a28e9bf5-7956-4c63-9129-7f2cbc468075",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__       = \"Christopher Potts and Omar Khattab\"\n",
    "__version__      = \"CS224u, Stanford, Spring 2023\"\n",
    "__completed_by__ = \"Anthony Weng\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5d964-a45c-496a-bb46-8f31d7b2d591",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/master/hw_openqa.ipynb)\n",
    "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/cgpotts/cs224u/blob/master/hw_openqa.ipynb)\n",
    "\n",
    "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570fc5-2ac0-4c0e-b350-71990937ebd8",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da2d82-8c54-4d41-a59d-891f83f85f6e",
   "metadata": {},
   "source": [
    "The goal of this homework is to explore retrieval-augmented in-context learning. This is an exciting area that brings together a number of recent task ideas and modeling innovations. We will use the [DSP programming library](https://github.com/stanfordnlp/dsp) to build systems in this new mode.\n",
    "\n",
    "Our core task is __open-domain question answering (OpenQA)__. In this task, all that is given by the dataset is a question text, and the task is to answer that question. By contrast, in modern QA tasks, the dataset provides a text and a gold passage, usually with a firm guarantee that the answer will be a substring of the passage. \n",
    "\n",
    "OpenQA is substantially harder than standard QA. The usual strategy is to use a _retriever_ to find passages in a large collection of texts and train a _reader_ to find answers in those passages. This means we have no guarantee that the retrieved passage will contain the answer we need. If we don't retrieve a passage containing the answer, our reader has no hope of succeeding. Although this is challenging, it is much more realistic and widely applicable than standard QA. After all, with the right retriever, an OpenQA system could be deployed over the entire Web.\n",
    "\n",
    "The task posed by this homework is harder even than OpenQA. We are calling this task __few-shot OpenQA__. The defining feature of this task is that the reader is simply a frozen, general purpose language model. It accepts string inputs (prompts) and produces text in response. It is not trained to answer questions per se, and nothing about its structure ensures that it will respond with a substring of the prompt corresponding to anything like an answer.\n",
    "\n",
    "__Few-shot QA__ (but not OpenQA!) is explored in the famous GPT-3 paper ([Brown et al. 2020](https://arxiv.org/abs/2005.14165)). The authors are able to get traction on the problem using GPT-3, an incredible finding. Our task here – __few-shot OpenQA__ – pushes this even further by retrieving passages to use in the prompt rather than assuming that the gold passage can be used in the prompt. If we can make this work, then it should be a major step towards flexibly and easily deploying QA technologies in new domains.\n",
    "\n",
    "In summary:\n",
    "\n",
    "| Task             | Passage given | Task-specific reader training |Task-specific retriever training  | \n",
    "|-----------------:|:-------------:|:-----------------------------:|:--------------------------------:|\n",
    "| QA               | yes           | yes                           | n/a                              |\n",
    "| OpenQA           | no            | yes                           | maybe                            |\n",
    "| Few-shot QA      | yes           | no                            | n/a                              |\n",
    "| Few-shot OpenQA  | no            | no                            | maybe                            | \n",
    "\n",
    "Just to repeat: your mission is to explore the final line in this table. The core notebook and assignment don't address the issue of training the retriever in a task-specific way, but this is something you could pursue for a final project; [the ColBERT codebase](https://github.com/stanford-futuredata/ColBERT) makes easy.\n",
    "\n",
    "As usual, this notebook sets up the task and provides starter code. We will be relying on the DSP library, which allows us to define retrieval-augmented in-context learning systems in code. We first provide two fully implemented examples:\n",
    "\n",
    "* _Few-shot OpenQA_: The given input is a question and the goal is to provide an answer. Some _demonstration_ Q/A pairs are sampled from a train set (in our case, SQuAD).\n",
    "\n",
    "* _Few-shot QA with context_: The given input is a question with an associated evidence passage, and the goal is to provide an answer. The _demonstrations_ are now Q/A pairs with associated gold evidence passages. These are sampled from a train set (in our case, SQuAD).\n",
    "\n",
    "The above examples are followed by some assignment questions aimed at helping you to think creatively about the problem. The first of these defines a core system for our target task:\n",
    "\n",
    "* _Few-shot OpenQA with context_: This is like _few-shot QA with context_ except the passages are now retrieved from a large search index using ColBERT. \n",
    "\n",
    "The second question illustrates how to use the powerful DSP `annotate` function to improve the set of demonstrations used by the system.\n",
    "\n",
    "It is a requirement of the bake-off that a general-purpose language model be used. In particular, trained QA systems cannot be used at all, and no fine-tuning is allowed either. See the original system question at the bottom of this message for guidance on which models are allowed.\n",
    "\n",
    "Note: the models we are working with here are _big_. This poses a challenge that is increasingly common in NLP: you have to pay one way or another. You can pay to use the GPT-3 API, or you can pay to use an Eleuther model on a heavy-duty cluster computer, or you can pay with time by using an Eleuther model on a more modest computer.  __For now, though, the Cohere models are free to use, so they should be your first choice; see [setup.ipynb](setup.ipynb) if you don't have an account__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd32bb4-067f-4cd6-943f-3e5574400beb",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bcb0f-bc76-4277-a359-742d6dcee063",
   "metadata": {},
   "source": [
    "We have sought to make this notebook self-contained and easy to use on a personal computer, on Google Colab, and in Sagemaker Studio. For personal computer use, we assume you have already done everything in [setup.ipynb](setup.ipynb]). For cloud usage, the next few code blocks should handle all set-up steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62b983bb-a20a-4c2a-9eee-9c553dd8c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import datasets\n",
    "    root_path = '.'\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/cgpotts/cs224u/\n",
    "    !pip install -r cs224u/requirements.txt\n",
    "    root_path = 'dsp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a04cb488-cd40-4f9d-b884-8ff83b012042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import os\n",
    "import dsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c9da704b-d27b-480a-93b5-e16cf7c51803",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "\n",
    "openai_key = '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'  # or replace with your API key (optional)\n",
    "\n",
    "cohere_key = 'SQg9nARczH2C1kAqppkQliLbJJbituSNLbt6LuNm'  # or replace with your API key (optional)\n",
    "\n",
    "colbert_server = 'http://ec2-44-228-128-229.us-west-2.compute.amazonaws.com:8893/api/search'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fc500-bbab-48b7-a704-67c6d57bb09b",
   "metadata": {},
   "source": [
    "Here we establish the Language Model `lm` and Retriever Model `rm` that we will be using. The defaults for `lm` are just for development. You may want to develop using an inexpensive model and then do your final evalautions wih an expensive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c118b014-e13f-433d-ad60-074636c7e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dsp.GPT3(model='text-davinci-001', api_key=openai_key)\n",
    "\n",
    "# Options for Cohere: command-medium-nightly, command-xlarge-nightly\n",
    "# lm = dsp.Cohere(model='command-medium-nightly', api_key=cohere_key)\n",
    "\n",
    "rm = dsp.ColBERTv2(url=colbert_server)\n",
    "\n",
    "dsp.settings.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711785d7-6bb9-4041-92e6-cc5f9308477e",
   "metadata": {},
   "source": [
    "Here's a command you can run to see which OpenAI models are available; OpenAI has entered into an increasingly closed mode where many older models are not available, so there are likely to be some surprises lurking here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8a859fbb-e985-4031-b8ed-34f3b034db8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['babbage',\n",
       " 'davinci',\n",
       " 'text-davinci-edit-001',\n",
       " 'babbage-code-search-code',\n",
       " 'text-similarity-babbage-001',\n",
       " 'code-davinci-edit-001',\n",
       " 'text-davinci-001',\n",
       " 'text-davinci-003',\n",
       " 'ada',\n",
       " 'babbage-code-search-text',\n",
       " 'babbage-similarity',\n",
       " 'gpt-3.5-turbo',\n",
       " 'code-search-babbage-text-001',\n",
       " 'text-curie-001',\n",
       " 'whisper-1',\n",
       " 'code-search-babbage-code-001',\n",
       " 'text-ada-001',\n",
       " 'text-embedding-ada-002',\n",
       " 'text-similarity-ada-001',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'curie-instruct-beta',\n",
       " 'ada-code-search-code',\n",
       " 'ada-similarity',\n",
       " 'code-search-ada-text-001',\n",
       " 'text-search-ada-query-001',\n",
       " 'davinci-search-document',\n",
       " 'ada-code-search-text',\n",
       " 'text-search-ada-doc-001',\n",
       " 'davinci-instruct-beta',\n",
       " 'text-similarity-curie-001',\n",
       " 'code-search-ada-code-001',\n",
       " 'ada-search-query',\n",
       " 'text-search-davinci-query-001',\n",
       " 'curie-search-query',\n",
       " 'davinci-search-query',\n",
       " 'babbage-search-document',\n",
       " 'ada-search-document',\n",
       " 'text-search-curie-query-001',\n",
       " 'text-search-babbage-doc-001',\n",
       " 'curie-search-document',\n",
       " 'text-search-curie-doc-001',\n",
       " 'babbage-search-query',\n",
       " 'text-babbage-001',\n",
       " 'text-search-davinci-doc-001',\n",
       " 'text-search-babbage-query-001',\n",
       " 'curie-similarity',\n",
       " 'curie',\n",
       " 'text-similarity-davinci-001',\n",
       " 'text-davinci-002',\n",
       " 'davinci-similarity',\n",
       " 'cushman:2020-05-03',\n",
       " 'ada:2020-05-03',\n",
       " 'babbage:2020-05-03',\n",
       " 'curie:2020-05-03',\n",
       " 'davinci:2020-05-03',\n",
       " 'if-davinci-v2',\n",
       " 'if-curie-v2',\n",
       " 'if-davinci:3.0.0',\n",
       " 'davinci-if:3.0.0',\n",
       " 'davinci-instruct-beta:2.0.0',\n",
       " 'text-ada:001',\n",
       " 'text-davinci:001',\n",
       " 'text-curie:001',\n",
       " 'text-babbage:001']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[\"root\"] for d in openai.Model.list()[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b3dc2-87d7-4b8b-b603-ee567e008710",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de295d35-fea5-46d2-9a01-022ad88e54cd",
   "metadata": {},
   "source": [
    "Our core development dataset is [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/). We chose this dataset because it is well-known and widely used, and it is large enough to support lots of meaningful development work, without, though, being so large as to require lots of compute power. It is also useful that it has gold passages supporting the standard QA formulation, so we can see how well our LM performs with an \"oracle\" retriever that always retrieves the gold passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5eaf2fd0-d060-4100-8702-f7311efd6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/ad2we/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006966829299926758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31f9ce65b66471782a7c863ac0092ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36965402-e3da-4531-b7e9-4b12cebcdf30",
   "metadata": {},
   "source": [
    "The following utility just reads a SQuAD split in as a list of `SquadExample` instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "21ad3e0b-7662-43b8-9409-a1a57442458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_split(squad, split=\"validation\"):\n",
    "    \"\"\"\n",
    "    Use `split='train'` for the train split.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of SquadExample named tuples with attributes\n",
    "    id, title, context, question, answers\n",
    "\n",
    "    \"\"\"\n",
    "    data = zip(*[squad[split][field] for field in squad[split].features])\n",
    "    return [dsp.Example(id=eid, title=title, context=context, question=q, answer=a['text']) \n",
    "            for eid, title, context, q, a in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3847d38-4e70-46b7-bf46-4c8b784c5ee5",
   "metadata": {},
   "source": [
    "### SQuAD train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c91e1-586b-4747-be39-3092e60f182f",
   "metadata": {},
   "source": [
    "To build few-shot prompts, we will often sample SQuAD train examples, so we load that split here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "66c4feba-d580-4984-a449-0b92a53ef13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train = get_squad_split(squad, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab8c41-8eae-4d15-ad4d-e28b3c58eb4a",
   "metadata": {},
   "source": [
    "### SQuAD dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "37198b33-c47b-4e0e-af8b-c00860658cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev = get_squad_split(squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40c768-57cc-4a07-a3ef-5e34262b0ace",
   "metadata": {},
   "source": [
    "### SQuAD dev sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636601b5-c7ad-4177-a6d6-f3afdb0bedae",
   "metadata": {},
   "source": [
    "Evaluations are expensive in this new era! Here's a small sample to use for dev assessments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3ecce47a-ecd2-4143-8c52-81700c060b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_exs = sorted(squad_dev, key=lambda x: hash(x.id))[: 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba48440-4a65-41e8-b397-7b79f65fa0fe",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8734a-49a1-4093-a2fb-09bb7d2f2859",
   "metadata": {},
   "source": [
    "Our evaluation protocols are the standard ones for SQuAD and related tasks: exact match of the answer (EM) and token-level F1. We'll reply primarily on DSP for these evaluation utilities; the following is a light modification of `dsp.evaluation.utils.evaluateAnswer`, which is itself built evaluation code from [apple/ml-qrecc](https://github.com/apple/ml-qrecc/blob/main/utils/evaluate_qa.py) repository. It performs very basic string normalization before doing the core comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5e8bf612-5195-4f4a-b72a-bf9faf128142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import EM, F1\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluateAnswer(fn, dev):\n",
    "    \"\"\"Evaluate a DSP program on `dev`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fn : DSP system\n",
    "    dev : list of `dsp.Example` instances\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys \"df\", \"em\", \"f1\" storing assessment data\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for example in tqdm.tqdm(dev):\n",
    "        prediction = fn(example)\n",
    "        d = dict(example)\n",
    "        pred = prediction.answer\n",
    "        d['prediction'] = pred\n",
    "        d['em'] = EM(pred, example.answer)\n",
    "        d['f1'] = F1(pred, example.answer)\n",
    "        data.append(d)\n",
    "    df = pd.DataFrame(data)\n",
    "    em = round(100.0 * df['em'].sum() / len(dev), 1)\n",
    "    df['em'] = df['em'].apply(lambda x: '✔️' if x else '❌')\n",
    "    f1 = df['f1'].mean()\n",
    "    return {'df': df, 'em': em, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28265d01-890d-4f04-b518-da0e8a1cb235",
   "metadata": {},
   "source": [
    "## DSP basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b9d12-fc8c-4aae-b09e-0d72a4aa54f5",
   "metadata": {},
   "source": [
    "### LM usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278daac-11f9-4327-a06f-1c408a06a71d",
   "metadata": {},
   "source": [
    "Here's the most basic way to use the LM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "02364ed6-3c6d-4eaf-849a-2d9e30d84b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nAlaska and Hawaii are the only U.S. states that border no other U.S. states.']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Which U.S. states border no U.S. states?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356d9a8-750b-4383-bc5b-4173ca5c13ac",
   "metadata": {},
   "source": [
    "Keyword arguments to the underlying LM are passed through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "19ab8deb-3b9d-4f57-bd70-7c170be294c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nAlaska and Hawaii are the only U.S. states that border no other U.S. states.',\n",
       " '\\n\\nAlaska and Hawaii are the only U.S. states that border no other U.S. states.',\n",
       " '\\n\\nAlaska and Hawaii are the only U.S. states that border no other U.S. states.']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Which U.S. states border no U.S. states?\", temperature=0.5, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e8d99-6d49-420d-ab5d-cc01b53cd4a1",
   "metadata": {},
   "source": [
    "With `lm.inspect_history`, we can see the most recent language model calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4f7cb5a5-3a3f-4e78-b9af-488fadc896ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Which U.S. states border no U.S. states?\u001b[32m\n",
      "\n",
      "If you include Alaska, then the U.S. states that border no other U.S. states are Hawaii, California, Oregon, and Washington.\u001b[0m\u001b[31m \t (and 3 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0f2df-df1f-422d-bff3-6c4a3d947f6e",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d49d4-f690-496a-a0ab-341096d8c1fb",
   "metadata": {},
   "source": [
    "In DSP, the more usual way to call the LM is to define a prompt template. Here we define a generic QA prompt template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4f6f50d6-e296-412f-a959-62e776b6f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = dsp.Type(\n",
    "    prefix=\"Question:\", \n",
    "    desc=\"${the question to be answered}\")\n",
    "\n",
    "Answer = dsp.Type(\n",
    "    prefix=\"Answer:\", \n",
    "    desc=\"${a short factoid answer, often between 1 and 5 words}\", \n",
    "    format=dsp.format_answers)\n",
    "\n",
    "qa_template = dsp.Template(\n",
    "    instructions=\"Answer questions with short factoid answers.\", \n",
    "    question=Question(), \n",
    "    answer=Answer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd383f-aa80-44ab-a381-f53e3b8e6631",
   "metadata": {},
   "source": [
    "And here is a self-contained example that uses our question and template to create a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b846dd8b-f8d6-44c6-9079-342bc3f54969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What album made her a worldwide known artist?\n",
      "Answer: Dangerously in Love\n",
      "\n",
      "Question: Immunoassays are able to detect what type of proteins?\n",
      "Answer: generated by an infected organism in response to a foreign agent\n",
      "\n",
      "Question: Which U.S. states border no U.S. states?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "states_ex = dsp.Example(\n",
    "    question=\"Which U.S. states border no U.S. states?\",\n",
    "    demos=dsp.sample(squad_train, k=2))\n",
    "\n",
    "print(qa_template(states_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58e275-99a9-45dc-8ae9-fcbdc191f66b",
   "metadata": {},
   "source": [
    "### Prompt-based generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0be5e0-7e7f-4e81-bcc0-4ce7a882eecd",
   "metadata": {},
   "source": [
    "We can how put the above pieces together to call the model with our constructed prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9c7d277c-a0aa-46c7-b0c3-1c7264efe75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_ex, states_compl = dsp.generate(qa_template)(states_ex, stage='basics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "413b75c4-8706-4936-a26b-b45c254b3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska, Hawaii\n"
     ]
    }
   ],
   "source": [
    "print(states_compl.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8460291-5c58-44bf-9d7e-02176ee6fc43",
   "metadata": {},
   "source": [
    "And here's precisely what the model saw and did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "820774e4-339f-4263-9493-9f91e7743a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What album made her a worldwide known artist?\n",
      "Answer: Dangerously in Love\n",
      "\n",
      "Question: Immunoassays are able to detect what type of proteins?\n",
      "Answer: generated by an infected organism in response to a foreign agent\n",
      "\n",
      "Question: Which U.S. states border no U.S. states?\n",
      "Answer:\u001b[32m Alaska, Hawaii\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1b41d-760c-4f28-8a2d-7f037b4f9d97",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4c8f4-a537-4d9b-9500-f881fceef1de",
   "metadata": {},
   "source": [
    "The final major component of our systems is retrieval. When we defined `rm`, we connected to a remote ColBERT index and retriever system that we can now use for search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2e395070-4c6f-4194-81ff-331e32eecd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which U.S. states border no U.S. states?'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_ex.question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfd114-96cf-468a-bac3-d3d39d6f3ca6",
   "metadata": {},
   "source": [
    "The basic `dsp.retrieve` method returns only passages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "891fc391-c177-4da7-9332-ab20cdba3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = dsp.retrieve(states_ex.question, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "abdac37b-b5fe-421c-826f-4fd699cb2e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mexico–United States border | has the shortest. Among the states in Mexico, Chihuahua has the longest border with the United States, while Nuevo León has the shortest. Texas borders four Mexican states—Tamaulipas, Nuevo León, Coahuila, and Chihuahua—the most of any U.S. states. New Mexico and Arizona each borders two Mexican states (Chihuahua and Sonora; Sonora and Baja California, respectively). California borders only Baja California. Three Mexican states border two U.S. states each: Baja California borders California and Arizona; Sonora borders Arizona and New Mexico; and Chihuahua borders New Mexico and Texas. Tamaulipas, Nuevo León, and Coahuila each borders only one U.S. state: Texas. The']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1f577-408c-4ede-9e27-65a24aafca5f",
   "metadata": {},
   "source": [
    "If we need passages with scores and other metadata, we can call `rm` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "37f4ff3d-de41-4fc7-8943-6dfd894dd1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pid': 6140356,\n",
       "  'prob': 1.0,\n",
       "  'rank': 1,\n",
       "  'score': 22.40652084350586,\n",
       "  'text': 'Mexico–United States border | has the shortest. Among the states in Mexico, Chihuahua has the longest border with the United States, while Nuevo León has the shortest. Texas borders four Mexican states—Tamaulipas, Nuevo León, Coahuila, and Chihuahua—the most of any U.S. states. New Mexico and Arizona each borders two Mexican states (Chihuahua and Sonora; Sonora and Baja California, respectively). California borders only Baja California. Three Mexican states border two U.S. states each: Baja California borders California and Arizona; Sonora borders Arizona and New Mexico; and Chihuahua borders New Mexico and Texas. Tamaulipas, Nuevo León, and Coahuila each borders only one U.S. state: Texas. The',\n",
       "  'long_text': 'Mexico–United States border | has the shortest. Among the states in Mexico, Chihuahua has the longest border with the United States, while Nuevo León has the shortest. Texas borders four Mexican states—Tamaulipas, Nuevo León, Coahuila, and Chihuahua—the most of any U.S. states. New Mexico and Arizona each borders two Mexican states (Chihuahua and Sonora; Sonora and Baja California, respectively). California borders only Baja California. Three Mexican states border two U.S. states each: Baja California borders California and Arizona; Sonora borders Arizona and New Mexico; and Chihuahua borders New Mexico and Texas. Tamaulipas, Nuevo León, and Coahuila each borders only one U.S. state: Texas. The'}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm(states_ex.question, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2017ee-1375-4251-a24f-7f792852ffac",
   "metadata": {},
   "source": [
    "## Few-shot OpenQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1dc2c2-8d8b-4cd2-a40f-ee023932359a",
   "metadata": {},
   "source": [
    "With the above pieces in place, we can define our first DSP system. This one does few-shot OpenQA with no context passages. In essense, our prompts contain\n",
    "\n",
    "1. A sequences of Q/A demonstrations (no context passages).\n",
    "2. The target question (no context passage).\n",
    "\n",
    "Here is the full system; note the use of the decorator `@dsp.transformation` – this will ensure that no `example` instances are modified when the program is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df25de1c-ee5c-42ec-b1f0-a7194ba6063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsp.transformation\n",
    "def few_shot_openqa(example, train=squad_train, k=2): \n",
    "    example.demos = dsp.sample(train, k=k)\n",
    "    example, completions = dsp.generate(qa_template)(example, stage='qa')\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952dd9d4-ba1f-4689-a548-4e216610f268",
   "metadata": {},
   "source": [
    "There are really just two steps here. Let's go through them individually. Our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b15bb28d-d46e-4a26-ab01-42c73ef953ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answer': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = squad_dev[0].copy()\n",
    "\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8407fb-a556-45f0-9c2a-92d08fbba5f7",
   "metadata": {},
   "source": [
    "We add some demonstrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1cb1e73b-7368-4b95-bf63-d4ef05f1ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answer': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       " 'demos': [{'id': '56bf6b0f3aeaaa14008c9604',\n",
       "   'title': 'Beyoncé',\n",
       "   'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "   'question': 'What album made her a worldwide known artist?',\n",
       "   'answer': ['Dangerously in Love']},\n",
       "  {'id': '57342720d058e614000b6a29',\n",
       "   'title': 'Infection',\n",
       "   'context': \"Complex serological techniques have been developed into what are known as Immunoassays. Immunoassays can use the basic antibody – antigen binding as the basis to produce an electro - magnetic or particle radiation signal, which can be detected by some form of instrumentation. Signal of unknowns can be compared to that of standards allowing quantitation of the target antigen. To aid in the diagnosis of infectious diseases, immunoassays can detect or measure antigens from either infectious agents or proteins generated by an infected organism in response to a foreign agent. For example, immunoassay A may detect the presence of a surface protein from a virus particle. Immunoassay B on the other hand may detect or measure antibodies produced by an organism's immune system that are made to neutralize and allow the destruction of the virus.\",\n",
       "   'question': 'Immunoassays are able to detect what type of proteins?',\n",
       "   'answer': ['generated by an infected organism in response to a foreign agent']}]}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.demos = dsp.sample(squad_train, k=2)\n",
    "\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae66b9f-ff8d-4952-bc59-f2da0d949089",
   "metadata": {},
   "source": [
    "And then we call the LM using `qa_template`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fc564cf6-d1d2-4a11-b0f2-58bfce3e34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex, ex_compl = dsp.generate(qa_template)(ex, stage='qa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000eec9-a63b-41fc-9641-60110996f231",
   "metadata": {},
   "source": [
    "Here, `ex_compl` is a `Completions` instance. We will typically use only the `answer` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ba4656bd-2f21-47b0-85f7-91720076be6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denver Broncos\n"
     ]
    }
   ],
   "source": [
    "print(ex_compl.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c0a19-84c4-4342-ac54-4750a2e70710",
   "metadata": {},
   "source": [
    "And, as a final check, we can see precisely what the LM saw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "57cb7634-4f80-4f8a-a855-f96c696717ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What album made her a worldwide known artist?\n",
      "Answer: Dangerously in Love\n",
      "\n",
      "Question: Immunoassays are able to detect what type of proteins?\n",
      "Answer: generated by an infected organism in response to a foreign agent\n",
      "\n",
      "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
      "Answer:\u001b[32m Denver Broncos\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b36c9-5549-4e67-8f07-c640229e69cc",
   "metadata": {},
   "source": [
    "## Few-shot QA with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888840f-27d4-4f09-bcdc-6a95946fa8c5",
   "metadata": {},
   "source": [
    "The above system makes no use of evidence passages. As a first step toward bringing in such passages, we define a regular few-shot QA system. For this system, prompts contain:\n",
    "\n",
    "1. A sequences of Q/A demonstrations, each with a gold context passage.\n",
    "2. The target question with a gold context passage.\n",
    "\n",
    "This kind of system is very demanding in terms of data, since we need to have gold evidence passages for every Q/A pair used for demonstations and the Q that is our target. Datasets like SQuAD support this, but it's a rare situation in the world. (Our next system will address this by dropping the need for gold passages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d451db1-a2c3-4c4f-982f-3a00e58c3ff6",
   "metadata": {},
   "source": [
    "### Template with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67513718-09e7-4386-ab78-aabac3b6e9ef",
   "metadata": {},
   "source": [
    "The first step toward defining this system is a new prompt template that includes context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47cd46e0-ca91-4fe3-bd2c-e4005a16669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Context = dsp.Type(\n",
    "    prefix=\"Context:\",\n",
    "    desc=\"${sources that may contain relevant content}\",\n",
    "    format=dsp.passages2text)\n",
    "\n",
    "qa_template_with_passages = dsp.Template(\n",
    "    instructions=qa_template.instructions,\n",
    "    context=Context(), \n",
    "    question=Question(), \n",
    "    answer=Answer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24aefd-0aa9-4b82-b8c3-42a06247bd14",
   "metadata": {},
   "source": [
    "Here's what this does for a SQUaD example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9c0b3571-16e6-48a0-9225-e92430ed0082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${sources that may contain relevant content}\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "Question: What album made her a worldwide known artist?\n",
      "Answer: Dangerously in Love\n",
      "\n",
      "Context: Complex serological techniques have been developed into what are known as Immunoassays. Immunoassays can use the basic antibody – antigen binding as the basis to produce an electro - magnetic or particle radiation signal, which can be detected by some form of instrumentation. Signal of unknowns can be compared to that of standards allowing quantitation of the target antigen. To aid in the diagnosis of infectious diseases, immunoassays can detect or measure antigens from either infectious agents or proteins generated by an infected organism in response to a foreign agent. For example, immunoassay A may detect the presence of a surface protein from a virus particle. Immunoassay B on the other hand may detect or measure antibodies produced by an organism's immune system that are made to neutralize and allow the destruction of the virus.\n",
      "Question: Immunoassays are able to detect what type of proteins?\n",
      "Answer: generated by an infected organism in response to a foreign agent\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_template_with_passages(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0a313-ba07-4b1d-9da4-a3fbf11321ca",
   "metadata": {},
   "source": [
    "### The system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a7406-dc46-4d6a-af19-198c11214211",
   "metadata": {},
   "source": [
    "And here is the full system; the code is identical to `few_shot_openqa` except we now use `qa_template_with_passages`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90323a84-b5bb-4bb0-a20e-ee89d85d09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsp.transformation\n",
    "def few_shot_qa_with_context(example, train=squad_train, k=3):\n",
    "    example.demos = dsp.sample(train, k=k)\n",
    "    generator = dsp.generate(qa_template_with_passages)\n",
    "    example, completions = generator(example, stage='qa')\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4871b0f5-f736-4d85-bfbe-199be78ff4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denver Broncos\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_qa_with_context(squad_dev[0]).answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9f6d5962-0993-4cac-9fc0-8ed18f608e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${sources that may contain relevant content}\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "Question: What album made her a worldwide known artist?\n",
      "Answer: Dangerously in Love\n",
      "\n",
      "Context: Complex serological techniques have been developed into what are known as Immunoassays. Immunoassays can use the basic antibody – antigen binding as the basis to produce an electro - magnetic or particle radiation signal, which can be detected by some form of instrumentation. Signal of unknowns can be compared to that of standards allowing quantitation of the target antigen. To aid in the diagnosis of infectious diseases, immunoassays can detect or measure antigens from either infectious agents or proteins generated by an infected organism in response to a foreign agent. For example, immunoassay A may detect the presence of a surface protein from a virus particle. Immunoassay B on the other hand may detect or measure antibodies produced by an organism's immune system that are made to neutralize and allow the destruction of the virus.\n",
      "Question: Immunoassays are able to detect what type of proteins?\n",
      "Answer: generated by an infected organism in response to a foreign agent\n",
      "\n",
      "Context: From the 10th to the 13th century, Romanesque architecture had become a pan-European style and manner of construction, affecting buildings in countries as far apart as Ireland, Croatia, Sweden and Sicily. The same wide geographic area was then affected by the development of Gothic architecture, but the acceptance of the Gothic style and methods of construction differed from place to place, as did the expressions of Gothic taste. The proximity of some regions meant that modern country borders do not define divisions of style. On the other hand, some regions such as England and Spain produced defining characteristics rarely seen elsewhere, except where they have been carried by itinerant craftsmen, or the transfer of bishops. Regional differences that are apparent in the great abbey churches and cathedrals of the Romanesque period often become even more apparent in the Gothic.\n",
      "Question: Why did country borders not affect differences in style within Gothic architecture?\n",
      "Answer: proximity of some regions\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
      "Answer:\u001b[32m Denver Broncos\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad912442-d489-48a7-90b3-eb85d5318771",
   "metadata": {},
   "source": [
    "## Dev evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204ad57-6d89-44f3-bde4-d788784a9fff",
   "metadata": {},
   "source": [
    "This quick section shows some full evaluations using `evaluateAnswer` (see [Evaluation](#Evaluation) above). Depending on which model you're using, these evaluations could be expensive, so you might want to run them only sparingly. Here I am running them on just 25 dev examples to further avoid cost run-ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5465c228-9ada-4c70-a694-669b9629ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_dev = dev_exs[: 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28ea0d8d-e51a-4b06-b7c7-aed2fcadb74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:19<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "0.251985347985348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_openqa_results = evaluateAnswer(few_shot_openqa, tiny_dev)\n",
    "\n",
    "print(few_shot_openqa_results['em'])\n",
    "print(few_shot_openqa_results['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39992dc4-c066-453e-8e1a-247823b41865",
   "metadata": {},
   "source": [
    "You can also see the full set of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47d06cbf-1a36-4492-8b2a-7ffdb1e324e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>em</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572825714b864d1900164594</td>\n",
       "      <td>Doctor_Who</td>\n",
       "      <td>TVOntario picked up the show in 1976 beginning...</td>\n",
       "      <td>What science fiction writer introduced the Doc...</td>\n",
       "      <td>[Judith Merril, Judith Merril, Judith Merril]</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56dde0ba66d3e219004dad76</td>\n",
       "      <td>Normans</td>\n",
       "      <td>In the course of the 10th century, the initial...</td>\n",
       "      <td>Who did Rollo sign the treaty of Saint-Clair-s...</td>\n",
       "      <td>[King Charles III, King Charles III, King Char...</td>\n",
       "      <td>Charles the Simple</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5725c7f5271a42140099d1a2</td>\n",
       "      <td>Apollo_program</td>\n",
       "      <td>Wiesner kept up the pressure, even making the ...</td>\n",
       "      <td>What did Wiesner shout out in front of the pre...</td>\n",
       "      <td>[\"No, that's no good\", \"No, that's no good, No...</td>\n",
       "      <td>He shouted \"Heil Hitler!\"</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56beb86b3aeaaa14008c92be</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Peyton Manning became the first quarterback ev...</td>\n",
       "      <td>Who previously held the record for being the o...</td>\n",
       "      <td>[John Elway, John Elway, Elway, Elway]</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57281cb22ca10214002d9e20</td>\n",
       "      <td>Doctor_Who</td>\n",
       "      <td>Six soundtrack releases have been released sin...</td>\n",
       "      <td>What music did the fourth soundtrack feature?</td>\n",
       "      <td>[music from the 2008–2010 specials, the 2008–2...</td>\n",
       "      <td>\"The Battle of the Five Armies\"</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id           title  \\\n",
       "0  572825714b864d1900164594      Doctor_Who   \n",
       "1  56dde0ba66d3e219004dad76         Normans   \n",
       "2  5725c7f5271a42140099d1a2  Apollo_program   \n",
       "3  56beb86b3aeaaa14008c92be   Super_Bowl_50   \n",
       "4  57281cb22ca10214002d9e20      Doctor_Who   \n",
       "\n",
       "                                             context  \\\n",
       "0  TVOntario picked up the show in 1976 beginning...   \n",
       "1  In the course of the 10th century, the initial...   \n",
       "2  Wiesner kept up the pressure, even making the ...   \n",
       "3  Peyton Manning became the first quarterback ev...   \n",
       "4  Six soundtrack releases have been released sin...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What science fiction writer introduced the Doc...   \n",
       "1  Who did Rollo sign the treaty of Saint-Clair-s...   \n",
       "2  What did Wiesner shout out in front of the pre...   \n",
       "3  Who previously held the record for being the o...   \n",
       "4      What music did the fourth soundtrack feature?   \n",
       "\n",
       "                                              answer  \\\n",
       "0      [Judith Merril, Judith Merril, Judith Merril]   \n",
       "1  [King Charles III, King Charles III, King Char...   \n",
       "2  [\"No, that's no good\", \"No, that's no good, No...   \n",
       "3             [John Elway, John Elway, Elway, Elway]   \n",
       "4  [music from the 2008–2010 specials, the 2008–2...   \n",
       "\n",
       "                        prediction em   f1  \n",
       "0                    Douglas Adams  ❌  0.0  \n",
       "1               Charles the Simple  ❌  0.4  \n",
       "2        He shouted \"Heil Hitler!\"  ❌  0.0  \n",
       "3                        Tom Brady  ❌  0.0  \n",
       "4  \"The Battle of the Five Armies\"  ❌  0.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_openqa_results['df'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb28556-d901-4b6b-8a7d-93040203294d",
   "metadata": {},
   "source": [
    "## Question 1: Few-shot OpenQA with context [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f481081-3e16-4ccd-b379-c7e0c3011286",
   "metadata": {},
   "source": [
    "Your task here is to define a first instance of our target system: Few-shot OpenQA with context passages. To do this, you simply complete `few_shot_openqa_with_context`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6ca394a8-be1a-4dfb-b9f6-b40f6b1fb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsp.transformation\n",
    "def few_shot_openqa_with_context(example, train=squad_train, k=3):\n",
    "    \n",
    "    # Sample `k` demonstrations from `train`:\n",
    "    ##### YOUR CODE HERE\n",
    "    demos = dsp.sample(train=train, k=k)\n",
    "\n",
    "    # For each demonstration, retrieve one passage and add it\n",
    "    # as the `context` attribute` so we can use our template\n",
    "    # `qa_template_with_passages`:\n",
    "    ##### YOUR CODE HERE\n",
    "    for demo in demos: \n",
    "        passage = dsp.retrieve(demo.question, k=1)\n",
    "        demo.context = passage\n",
    "\n",
    "    # Add the list of demonstrations to `example` as the `demos` attribute:\n",
    "    ##### YOUR CODE HERE\n",
    "    example.demos = demos\n",
    "\n",
    "    # Retrieve a context passage for `example` itself and add it\n",
    "    # as the `context` attribute:\n",
    "    ##### YOUR CODE HERE\n",
    "    ex_context = dsp.retrieve(example.question, k=1)\n",
    "    example.context = ex_context\n",
    "\n",
    "    # Use `dsp.generate` to call the model on `example` using\n",
    "    # `qa_template_with_passages`:\n",
    "    ##### YOUR CODE HERE\n",
    "    ex, ex_compl = dsp.generate(qa_template_with_passages)(example, stage='qa')\n",
    "\n",
    "    # Return the Completions instance returned by `dsp.generate`:\n",
    "    ##### YOUR CODE HERE\n",
    "    return ex_compl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fd165-fd7f-4943-8af4-a83f0d976453",
   "metadata": {},
   "source": [
    "A quick test you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1568f224-e6bb-443c-ae75-dd55a062d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_few_shot_openqa_with_context(func):\n",
    "    ex = dsp.Example(question=\"Q0\", context=\"C0\", answer=[\"A0\"])\n",
    "    train = [\n",
    "        dsp.Example(question=\"Q1\", context=None, answer=[\"A1\"]),\n",
    "        dsp.Example(question=\"Q2\", context=None, answer=[\"A2\"]),\n",
    "        dsp.Example(question=\"Q3\", context=None, answer=[\"A3\"])]\n",
    "    compl = func(ex, train=train, k=2)\n",
    "    errcount = 0\n",
    "    # Check the LM was used as expected:\n",
    "    if len(compl.data) != 1:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: Unexpected LM output.\")\n",
    "    data = compl.data[0]\n",
    "    # Check that the right number of demos was used:\n",
    "    demos = data['demos']\n",
    "    if len(demos) > 2:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "              f\"Unexpected demo count: {len(demos)}\")\n",
    "    # Check that context passages were included in the prompt:\n",
    "    fields = compl.template.fields\n",
    "    if not any(f.name == 'Context:' for f in fields):\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "              f\"No context passages in the prompt.\")\n",
    "    # Check that the context passages were retrieved:\n",
    "    if data['context'] == \"C0\":\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "              f\"No context passage retrieved for the target.\")\n",
    "    for d in demos:\n",
    "        if d['context'] is None:\n",
    "            errcount += 1\n",
    "            print(f\"Error for `{func.__name__}`: \"\n",
    "                  f\"No context passage retrieved for demo {d}.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors found for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8efe5f07-df96-4d95-8334-8c4966b66269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found for `few_shot_openqa_with_context`\n"
     ]
    }
   ],
   "source": [
    "test_few_shot_openqa_with_context(few_shot_openqa_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2448dfa0-e945-44b6-a487-70e49675cf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthony Coburn\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_openqa_with_context(dev_exs[0]).answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e9855ec2-84cc-4a2f-ad47-502c26e44dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${sources that may contain relevant content}\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Context: «Janet (album) | worldwide sales of over 14 million copies, it is Janet's best selling album. Although Jackson has reached superstar status in the United States, she has yet to achieve the same level of response internationally. According to Nacy Berry, vice chairman of Virgin Records, \"Janet\" marked the first time the label \"had centrally coordinated and strategized a campaign on a worldwide basis\" which ultimately brought her to a plateau of global recognition. Her historic multimillion-dollar contract made her the highest-paid artist in history, until brother Michael renegotiated his contract with Sony Music Entertainment only days later. Sonia Murry noted that she»\n",
      "Question: What album made her a worldwide known artist?\n",
      "Answer: Dangerously in Love\n",
      "\n",
      "Context: «Oligoclonal band | immunoassay\" are able to detect IgG OCBs in more than 95% of multiple sclerosis patients. Even more than 12 OCBs can appear in MS. Each one of them represent antibody proteins (or protein fragments) secreted by plasma cells, although why exactly these bands are present, and which proteins these bands represent, has not yet been fully elucidated. The target antigens for these antibodies are not easy to find because it requires to isolate a single kind of protein in each band, though new techniques are able to do so. In 40% of MS patients with OCBs, antibodies specific to the»\n",
      "Question: Immunoassays are able to detect what type of proteins?\n",
      "Answer: generated by an infected organism in response to a foreign agent\n",
      "\n",
      "Context: «Gothic architecture | and Sweden and Sicily. The same wide geographic area was then affected by the development of Gothic architecture, but the acceptance of the Gothic style and methods of construction differed from place to place, as did the expressions of Gothic taste. The proximity of some regions meant that modern country borders did not define divisions of style. On the other hand, some regions such as England and Spain produced defining characteristics rarely seen elsewhere, except where they have been carried by itinerant craftsmen, or the transfer of bishops. Many different factors like geographical/geological, economic, social, or political situations caused the»\n",
      "Question: Why did country borders not affect differences in style within Gothic architecture?\n",
      "Answer: proximity of some regions\n",
      "\n",
      "Context: «An Unearthly Child | An Unearthly Child An Unearthly Child (sometimes referred to as 100,000 BC) is the first serial of the British science fiction television series \"Doctor Who\". It was first broadcast on BBC TV in four weekly parts from 23 November to 14 December 1963. Scripted by Australian writer Anthony Coburn, the serial introduces William Hartnell as the First Doctor and his original companions: Carole Ann Ford as the Doctor's granddaughter, Susan Foreman, with Jacqueline Hill and William Russell as school teachers Barbara Wright and Ian Chesterton. The first episode deals with Ian and Barbara's discovery of the Doctor and his time-space»\n",
      "Question: What science fiction writer introduced the Doctor Who episodes for a period of time?\n",
      "Answer:\u001b[32m Anthony Coburn\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddccccd5-78f9-47f6-b1d1-7f1171a12b51",
   "metadata": {},
   "source": [
    "Here's an optional evaluation of the system using `tiny_dev`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11f2f036-f18f-4be2-983f-283c07d3e019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:27<00:00,  1.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4861176470588235"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_openqa_with_context_results = evaluateAnswer(\n",
    "    few_shot_openqa_with_context, tiny_dev)\n",
    "\n",
    "few_shot_openqa_with_context_results['f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971ffd0-a563-4d56-a896-0735a63ae92f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: Using annotate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "054b0fbd-b21b-4b6f-a24c-54235ad1833a",
   "metadata": {},
   "source": [
    "This question is designed to give you some experience with DSP's powerful `annotate` method. You can think of this as a generic tool for defining general aspects of your prompt. Here we will use it to filter the set of demonstrations we use.\n",
    "\n",
    "The overall idea here is that the demonstrations we sample might vary in quality in ways that could impact model performance. For example, if we want to try to push the model to provide extractive answers as in classical QA – answers that are substrings of the evidence passage – then it works against our interests to include demonstrations where the model is unable to do this.\n",
    "\n",
    "We will do this in two parts to facilitate testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268d575-7cfc-4fb6-9d12-87fcc14c59c1",
   "metadata": {},
   "source": [
    "### Task 1: Filtering demonstrations 1 [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae208ecb-1569-4c4a-b105-828084f458ef",
   "metadata": {},
   "source": [
    "This is the heart of the question: complete `filter_demos` so that, given a demonstration `d` and a list of demonstrations `demos`, it keeps `d` if and only if\n",
    "\n",
    "1. The passage retrieved for `d` contrains `d.answer`, and\n",
    "2. The model's generation for `d` based on `qa_template_with_passages` contains `d.answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8d90e4d8-9ecb-4273-93f0-5d0550ec8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsp.transformation\n",
    "def filter_demos(d):\n",
    "\n",
    "    # Retrieve a passage for `d.question` and make sure that it\n",
    "    # contains `d.answer`. Use `dsp.passage_match` for this!\n",
    "    # return None if there is no match.\n",
    "    ##### YOUR CODE HERE\n",
    "    d_context = dsp.retrieve(d.question, k=1)\n",
    "    if not dsp.passage_match(d_context, d.answer): return None\n",
    "    d.context = d_context\n",
    "\n",
    "    # Sample `k=3` demonstrations to help the model assess this\n",
    "    # potential demonstration:\n",
    "    ##### YOUR CODE HERE\n",
    "    squad_demos = dsp.sample(train=squad_train, k=3)\n",
    "    d.demos = squad_demos\n",
    "\n",
    "    # Generate an answer based on `qa_template_with_passages`\n",
    "    # and use `dsp.answer_match` to check that the predicted answer\n",
    "    # contains `d.answer`. If it does not, return None.\n",
    "    ##### YOUR CODE HERE\n",
    "    ex, ex_compl = dsp.generate(qa_template_with_passages)(d, stage='qa')\n",
    "    if not dsp.answer_match(ex_compl.answer, d.answer): return None \n",
    "\n",
    "    # Return d, if you got this far:\n",
    "    ##### YOUR CODE HERE\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674c760-e507-4b60-9f17-5fc91500a68e",
   "metadata": {},
   "source": [
    "Here's a test; this is not an ideal unit test because we don't know which LM you will be using, but it should clarify our intentions and help you with debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "66812d32-cc0b-4736-8483-4bb3812f1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_filter_demos(func):\n",
    "    # This example should be filtered at the retrieval step, since\n",
    "    # 👽 is not in the index:\n",
    "    ex1 = dsp.Example(\n",
    "        question=\"Who is 👽?\", context=\"C0\", answer=[\"👽\"])\n",
    "    result1 = func(ex1)\n",
    "    errcount = 0\n",
    "    if result1 is not None:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{func.__name__}`: Expected {None}, got {result1}\")\n",
    "    # This example should not be filtered given our tester LM:\n",
    "    ex2 = dsp.Example(\n",
    "        question=\"Who is Beyoncé?\", context=\"C0\", answer=[\"Beyoncé\"])\n",
    "    # This example should be filtered given our tester LM:\n",
    "    ex3 = dsp.Example(\n",
    "        question=\"Who is Beyoncé?\", context=\"C0\", answer=[\"NO MATCH\"])\n",
    "    class TestLM:\n",
    "        def __init__(self, **kwargs):\n",
    "            self.kwargs = kwargs\n",
    "            self.history = []\n",
    "\n",
    "        def __call__(self, prompt, **kwargs):\n",
    "            answer = [\"Beyoncé\"]\n",
    "            return answer\n",
    "    dsp.settings.configure(lm=TestLM(), rm=rm)\n",
    "    try:\n",
    "        result2 = func(ex2)\n",
    "        if result2 is None:\n",
    "            errcount += 1\n",
    "            print(f\"Error for `{func.__name__}`: \"\n",
    "                  f\"Expected example not to be filtered by `answer_match`.\")\n",
    "        result3 = func(ex3)\n",
    "        if result3 is not None:\n",
    "            errcount += 1\n",
    "            print(f\"Error for `{func.__name__}`: \"\n",
    "                  f\"Expected example to be filtered by `answer_match`.\")\n",
    "    except:\n",
    "        raise\n",
    "    finally:\n",
    "        # Restore the actual model:\n",
    "        dsp.settings.configure(lm=lm, rm=rm)\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ef762c5a-68cf-422a-bec4-aa369f73aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `filter_demos`\n"
     ]
    }
   ],
   "source": [
    "test_filter_demos(filter_demos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b897f65-b966-499a-87f1-dd7f8625d069",
   "metadata": {},
   "source": [
    "### Task 2: Full filtering program [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08168b-64fe-4965-94f5-c3dc4675dc8a",
   "metadata": {},
   "source": [
    "The task is to complete `few_shot_openqa_with_context_and_demo_filtering` as a few-shot OpenQA system like the one from Question 1, but using the filtering mechanism defined by `filter_demos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e2d3601f-1f61-4f6a-b8d9-09ce515f19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsp.transformation\n",
    "def few_shot_openqa_with_context_and_demo_filtering(example, train=squad_train, k=3):\n",
    "\n",
    "    # Sample 20 demonstrations:\n",
    "    ##### YOUR CODE HERE\n",
    "    demos = dsp.sample(train=train, k=20)\n",
    "\n",
    "    # Filter the demonstrations using `annotate` and `filter_demos`.\n",
    "    # The user's `k` should be used to specify the maximum number of\n",
    "    # demonstrations kept at this stage.\n",
    "    ##### YOUR CODE HERE\n",
    "    filtered = dsp.annotate(filter_demos)(demos, k=k)\n",
    "\n",
    "    # Add the list of filtered demonstrations as the `demos`\n",
    "    # attribute of `example`:\n",
    "    ##### YOUR CODE HERE\n",
    "    example.demos = filtered\n",
    "\n",
    "    # Retrieve a context passage for `example.question` and add it\n",
    "    # as the `context` attribute for the example:\n",
    "    ##### YOUR CODE HERE\n",
    "    ex_context = dsp.retrieve(example.question, k=1)\n",
    "    example.context = ex_context\n",
    "\n",
    "    # Generate a prediction using `qa_template_with_passages` as\n",
    "    # we did before:\n",
    "    ##### YOUR CODE HERE\n",
    "    ex, ex_compl = dsp.generate(qa_template_with_passages)(example, stage='qa')\n",
    "    \n",
    "    # Return the generated `Completions` instance:\n",
    "    ##### YOUR CODE HERE\n",
    "    return ex_compl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4db956-79a8-4092-a553-91f0d79f3084",
   "metadata": {},
   "source": [
    "Our previous test should suffice to help with debugging this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4fc93545-cd13-49a3-840c-385d29bb397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found for `few_shot_openqa_with_context_and_demo_filtering`\n"
     ]
    }
   ],
   "source": [
    "test_few_shot_openqa_with_context(\n",
    "    few_shot_openqa_with_context_and_demo_filtering)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c55dbeb-031d-4429-8669-17162d2ea05b",
   "metadata": {},
   "source": [
    "Quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "26f0964f-136a-4e85-9944-4472dcd5cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthony Coburn\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_openqa_with_context_and_demo_filtering(dev_exs[0]).answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ea4224d4-cedc-4f58-a0b6-20b8f22d0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${sources that may contain relevant content}\n",
      "Question: ${the question to be answered}\n",
      "Answer: ${a short factoid answer, often between 1 and 5 words}\n",
      "\n",
      "---\n",
      "\n",
      "Context: «Adult Contemporary (chart) | An article on MTV's website by Corey Moss describes this trend: \"In other words, AC stations are where pop songs go to die a very long death. Or, to optimists, to get a second life.\" One theory states that many adult contemporary stations play less newer music because they also give ample airtime to hits of the past, so the de-emphasis on new songs slows the progression of the AC chart. Also, certain program directors have asserted that AC is a song-based format, as opposed to other radio formats that are infused with singer-based programming, so there is no guarantee»\n",
      "Question: What type of music are AC stations noted as playing less of versus hits of the past?\n",
      "Answer: newer music\n",
      "\n",
      "---\n",
      "\n",
      "Context: «Mayor of Richmond, Virginia | Mayor of Richmond, Virginia The Mayor of the City of Richmond, Virginia is head of the executive branch of Richmond, Virginia's city government. The mayor's office administers all city services, public property, police and fire protection, most public agencies, and enforces all city, state and federal laws within Richmond, Virginia. The mayor looks over a city budget at roughly $765 million a year. The current mayor is Democrat Levar Stoney, who was elected on November 8, 2016. Stoney took office on December 31, 2016. The mayor of Richmond contains a multi-member cabinet of advisers that assist the mayor on city»\n",
      "Question: What official is in charge of Richmond's executive branch?\n",
      "Answer: mayor\n",
      "\n",
      "---\n",
      "\n",
      "Context: «Joe Simon | Joe Simon Joseph Henry \"Joe\" Simon (born Hymie Simon; October 11, 1913 – December 14, 2011) was an American comic book writer, artist, editor, and publisher. Simon created or co-created many important characters like Captain America in the 1930s–1940s Golden Age of Comic Books and served as the first editor of Timely Comics, the company that would evolve into Marvel Comics. With his partner, artist Jack Kirby, he co-created Captain America, one of comics' most enduring superheroes, and the team worked extensively on such features at DC Comics as the 1940s Sandman and Sandy the Golden Boy, and co-created the»\n",
      "Question: Besides Simon, who co-created Captain America?\n",
      "Answer: Jack Kirby\n",
      "\n",
      "---\n",
      "\n",
      "Context: «An Unearthly Child | An Unearthly Child An Unearthly Child (sometimes referred to as 100,000 BC) is the first serial of the British science fiction television series \"Doctor Who\". It was first broadcast on BBC TV in four weekly parts from 23 November to 14 December 1963. Scripted by Australian writer Anthony Coburn, the serial introduces William Hartnell as the First Doctor and his original companions: Carole Ann Ford as the Doctor's granddaughter, Susan Foreman, with Jacqueline Hill and William Russell as school teachers Barbara Wright and Ian Chesterton. The first episode deals with Ian and Barbara's discovery of the Doctor and his time-space»\n",
      "Question: What science fiction writer introduced the Doctor Who episodes for a period of time?\n",
      "Answer:\u001b[32m Anthony Coburn\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae2262-3eea-487b-8e58-96f310892a19",
   "metadata": {},
   "source": [
    "Here is code for an optional initial evaluation with `tiny_dev`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c9c06c67-dd96-46f2-9fac-653d562fc385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:25<00:00,  3.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46799999999999997"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering_results = evaluateAnswer(\n",
    "    few_shot_openqa_with_context_and_demo_filtering, tiny_dev)\n",
    "\n",
    "filtering_results['f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19655d70-007c-4a41-9f3b-e20df9c5169b",
   "metadata": {},
   "source": [
    "## Question 3: Your original system [3 points]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d8d268f-70e1-4325-a2ff-7361d73788b9",
   "metadata": {},
   "source": [
    "This question asks you to design your own few-shot OpenQA system. All of the code above can be used and modified for this, and the requirement is just that you try something new that goes beyond what we've done so far. \n",
    "\n",
    "Terms for the bake-off:\n",
    "\n",
    "* You can make free use of SQuAD and other publicly available data.\n",
    "\n",
    "* The LM must be an autoregressive language model. No trained QA components can be used. This includes general purpose LMs that have been fine-tuned for QA. (We have obviously waded into some vague territory here. The spirit of this is to make use of frozen, general-purpose models. We welcome questions about exactly how this is defined, since it could be instructive to explore this.)\n",
    "\n",
    "Here are some ideas for the original system:\n",
    "\n",
    "* We have so far sampled randomly from the SQuaD train set to create few-shot prompts. One might instead sample passages that have some connection to the target question. See `dsp.knn`, for example.\n",
    "\n",
    "* There are a lot of parameters to our LMs that we have so far ignored. Exploring different values might lead to better results. The `temperature` parameter is highly impactful for our task.\n",
    "\n",
    "* We have so far made no use of the scores from the LM or the RM.\n",
    "\n",
    "* We have so far made no use of DSP's functionality for self-consistency. See the DSP intro notebook for examples.\n",
    "\n",
    "__Original system instructions__:\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b557f3c3-ee72-480e-9d99-9095372f99c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 25/25 [07:42<00:00, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exact matches :: 20.0 out of 25, F1 on evaluation set: 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "\"\"\"__system-description__\n",
    "This bakeoff system consists of two minor changes and one major change. \n",
    "\n",
    "Changes are as follows: \n",
    "1. [minor] The LM employed by the DSP program has been changed from 'text-davinci-001' \n",
    "   to 'gpt-3.5-turbo' to afford the DSP program the general improved performance and \n",
    "   expressiveness that comes with this larger, more powerful, and more expensive model. \n",
    "   \n",
    "2. [minor] In the call to instantiate the DSP `lm`, we specify the `temperature` \n",
    "   paramater to be set to 0.1 to strongly bias model responses toward those with \n",
    "   higher scores and associated certainty. \n",
    "   \n",
    "3. [major] The DSP program now utilizes a summary-based demonstration filtering \n",
    "   function which involves cosine similarity computations as a part of the \n",
    "   `dsp.annotate` call. The function which generates answers to given dsp.Example \n",
    "   questions (few_shot_openqa_with_custom_context_and_demo_filtering) also employs \n",
    "   cosine similarity-based filtering of potential context passages before summarizing \n",
    "   said passages with the summary being used as the context for question answering. \n",
    "   Further details on both components of this system are provided below. \n",
    "\n",
    "The inspiration for this system was my personal interpretation of how a \n",
    "human agent would answer a generic question without being given any kind \n",
    "of reference passage. In such a situation, I envisioned a human agent \n",
    "proceeding as follows: \n",
    "\n",
    "1. The agent will look up multiple context sources related to the question. \n",
    "\n",
    "2. The agent will assess whether each context source is sufficiently related \n",
    "   to the question (for some def. of sufficiently related).\n",
    "   \n",
    "3. After potentially filtering unrelated sources in the previous step, the agent \n",
    "   will summarize information presented across the remaining context sources, with \n",
    "   the summarization function acting as a natural language 'intersection' function \n",
    "   (in that the information common to all sources will likely be included in the \n",
    "   summary as if some factoid is present in all sources, it is likely of high truth \n",
    "   value and importance). \n",
    "   \n",
    "4. The agent will review the summary and use it to answer the question.\n",
    "\n",
    "A human agent may implicitly perform these operations, but for this DSP program, \n",
    "I seek to make each step explicit and reproducible. Their translation into code \n",
    "is as follows: \n",
    "\n",
    "When considering the demonstrations I want to provide to the DSP program for a \n",
    "given dsp.Example question, I want the demonstrations to represent successful \n",
    "enactments of the worklow described above. To that end, the demonstration \n",
    "filtering function (custom_filter_demos) used as a part of `dsp.annotate` to \n",
    "curate demonstrations operates as follows: \n",
    "\n",
    "1. For a given candidate demonstration d, I retrieve a few context passages for \n",
    "   the associated `d.question` and summarize them using an XLNet-based transformer \n",
    "   architecture designed for text summarization. \n",
    "   \n",
    "2. If the summary does not contain `d.answer` and/or if the answer generated using \n",
    "   the `qa_template_with_passages` template does not contain `d.answer`, the \n",
    "   demonstration is discarded.  \n",
    "   \n",
    "3. Since both the context summary and generated answer contain `d.answer`, this \n",
    "   is a signal that the originally retrieved context passages were 'sufficiently \n",
    "   related'to the demonstration's question. To codify this definition in a \n",
    "   quantitative way, for all non-discarded demonstrations, I embed the relevant \n",
    "   question and context passages using a general-purpose BERT-based sentence \n",
    "   embedding transformer architecture, compute the pairwise cosine similarity \n",
    "   between question and passage embeddings, and incrementally estimate the avg. \n",
    "   cosine similarity for all such pairs. This number, `AVG_COSINE_SIM` will be \n",
    "   relevant shortly.\n",
    "   \n",
    "With our demonstration filtering function defined, the actual question answering\n",
    "function, few_shot_openqa_with_custom_context_and_demo_filtering, works as follows: \n",
    "\n",
    "1. For a given dsp.Example, we begin by sampling a high-ish number (30) of \n",
    "   demonstrations and filter them (using dsp.annotate) according to our \n",
    "   previously-described filtering function. A maximum of some number (set \n",
    "   by a parameter) of these demonstrations are kept and provided to the \n",
    "   dsp.Example as demos. \n",
    "   \n",
    "2. Then, as many as 10 context passages are retrieved for the dsp.Example\n",
    "   question. The question and each context passage is embedded using the \n",
    "   same BERT-based sentence embedder used in the filtering function. \n",
    "   Pairwise cosine similarity between the question and context embeddings \n",
    "   are computed. \n",
    "   \n",
    "   All context passages whose embeddings share a cosine similarity of at\n",
    "   least `AVG_COSINE_SIM` (the metric defining 'sufficiently related' as \n",
    "   informed by retained demonstrations) are then summarized (using the \n",
    "   same XLNet-based summarizer as used in the filtering function) and \n",
    "   provided as the context for the dsp.Example question, which can then \n",
    "   be passed to the dsp lm for attempted question answering. \n",
    "\n",
    "Notes on imported model components: \n",
    "\n",
    "1. The summarizer is a version of the XLNet model. This model uses \n",
    "   generalized autoregressive pretraining which is not specific to \n",
    "   question answering. \n",
    "      - Link: https://huggingface.co/xlnet-base-cased.\n",
    "   \n",
    "2. The sentence embedder is based on the BERT architecture. It is a \n",
    "   fine-tuned version of the pretrained 'MiniLM-L6-H384-uncased' model.\n",
    "   Fine-tuning is performed with a contrastive learning objective not \n",
    "   specific to question answering. \n",
    "      - Link: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2.\n",
    "      \n",
    "3. The language model used by the DSP program is 'gpt-3.5-turbo' provided \n",
    "   by OpenAI. The model is optimized for chat completion which is not \n",
    "   specific to quesion answering. \n",
    "      - Link: https://platform.openai.com/docs/models/gpt-3-5. \n",
    "\"\"\"\n",
    "\n",
    "# additional imports: \n",
    "from summarizer             import TransformerSummarizer    # for summarizing context passages. \n",
    "from sentence_transformers  import SentenceTransformer      # for embedding sentences.\n",
    "from scipy.spatial.distance import cosine                   # for computing cosine similarity between text embeddings. \n",
    " \n",
    "import numpy as np\n",
    "\n",
    "# instantiate our summarizer and sentence embedding models: \n",
    "summarizer  = TransformerSummarizer(transformer_type=\"XLNet\", transformer_model_key=\"xlnet-base-cased\")\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# global variables: \n",
    "# (1) AVG_COSINE_SIM:\n",
    "#       the average cosine similarity between a demonstration question \n",
    "#       and its relevant context passages if said demonstration question\n",
    "#       can be answered by a summary of the context passages. \n",
    "# (2) NUM_EXS:\n",
    "#       the number of context passages observed in the demonstration   \n",
    "#       filtering and annotation process. \n",
    "AVG_COSINE_SIM, NUM_EXS = 0, 0  \n",
    "\n",
    "# change `lm` to more powerful (and expensive) 'gpt-3.5-turbo' model for evaluation.\n",
    "# when setting `lm`, set the temperature parameter near-ish 0 to bias toward answers\n",
    "# with higher scores/certainty.\n",
    "lm = dsp.GPT3(model='gpt-3.5-turbo', api_key=openai_key, temperature=0.1)\n",
    "dsp.settings.configure(lm=lm, rm=rm)\n",
    "\n",
    "@dsp.transformation\n",
    "def custom_filter_demos(d): \n",
    "    # retrieve a few context passages for `d.question` and summarize them \n",
    "    # using our previously-specified XLNet-based summarizer: \n",
    "    d_context = dsp.retrieve(d.question, k=5)\n",
    "    summary = ''.join(summarizer(' '.join(d_context), min_length = 60)) \n",
    "    \n",
    "    # check if the summary contains `d.answer`. if not, return None;\n",
    "    # if yes, assign `summary` to `d.context`: \n",
    "    if not dsp.passage_match([summary], d.answer): return None \n",
    "    d.context = summary \n",
    "    \n",
    "    # as with filter_demos(), sample `k=3` demonstrations to help \n",
    "    # the model assess this potential demonstration: \n",
    "    squad_demos = dsp.sample(train=squad_train, k=3)\n",
    "    d.demos = squad_demos \n",
    "    \n",
    "    # generate an answer based on `qa_template_with_passages`\n",
    "    # and use `dsp.answer_match` to check that the predicted answer \n",
    "    # contains `d.answer`. if it doesn't, return None: \n",
    "    _, ex_compl = dsp.generate(qa_template_with_passages)(d, stage='qa')\n",
    "    if not dsp.answer_match(ex_compl.answer, d.answer): return None \n",
    "    \n",
    "    # embed the `d.question` vector using the previously-specified \n",
    "    # BERT-based SentenceTransformer model: \n",
    "    d_question_vec = sbert_model.encode([d.question])[0]\n",
    "    \n",
    "    # emebd each of the context passages using the same model: \n",
    "    d_context_vecs = [sbert_model.encode([context_passage])[0] for context_passage in d_context]\n",
    "    \n",
    "    # compute the cosine distance between `d_question_vec` and \n",
    "    # each context vec. and incrementally update global vars. \n",
    "    # `AVG_COSINE_SIM` and `NUM_EXS`: \n",
    "    for context_vec in d_context_vecs: \n",
    "        question_context_sim = 1 - cosine(d_question_vec, context_vec)\n",
    "        global AVG_COSINE_SIM; global NUM_EXS\n",
    "        total_cosine_sim = AVG_COSINE_SIM * NUM_EXS \n",
    "        total_cosine_sim += question_context_sim \n",
    "        NUM_EXS += 1\n",
    "        AVG_COSINE_SIM = total_cosine_sim / NUM_EXS\n",
    "        \n",
    "    # return the demonstration: \n",
    "    return d \n",
    "\n",
    "@dsp.transformation\n",
    "def few_shot_openqa_with_custom_context_and_demo_filtering(example, train=squad_train, k=3): \n",
    "    # sample a high-ish number (30) of demonstrations: \n",
    "    demos = dsp.sample(train=train, k=30)\n",
    "    \n",
    "    # filter the demonstrations using `annotate` and `filter_demos`. \n",
    "    # the `k` provided in the function signature specifies the maximum \n",
    "    # number of demonstrations kept at this stage: \n",
    "    filtered = dsp.annotate(custom_filter_demos)(demos, k=k)\n",
    "    \n",
    "    # assign the list of filtered demonstrations to the `demos`\n",
    "    # attribute of `example`:\n",
    "    example.demos = filtered \n",
    "    \n",
    "    # retrieve many (10) context passages for `example.question`: \n",
    "    ex_context = dsp.retrieve(example.question, k=10)\n",
    "    \n",
    "    # embed `example.question` and the context passages using the \n",
    "    # BERT-based SentenceTransformer model: \n",
    "    q_vec = sbert_model.encode([ex.question])[0]\n",
    "    context_vecs = [sbert_model.encode([context_passage])[0] for context_passage in ex_context]\n",
    "    \n",
    "    # compute the cosine sim. between each context passage vector \n",
    "    # and the question vector: \n",
    "    cosine_sims = [1 - cosine(context_vec, q_vec) for context_vec in context_vecs]\n",
    "    \n",
    "    # determine which context vectors (and associated passages) \n",
    "    # have at least AVG_COSINE_SIM similarity with the question: \n",
    "    global AVG_COSINE_SIM\n",
    "    min_cosine_sim_achieved = ['T' if cos_sim >= AVG_COSINE_SIM else 'F' for cos_sim in cosine_sims]\n",
    "\n",
    "    # if no context vector achieves at least AVG_COSINE_SIM, then \n",
    "    # set the `example.context` to be the context passage for the \n",
    "    # vector with the highest cosine similarity with the question: \n",
    "    if 'T' not in min_cosine_sim_achieved: \n",
    "        index_max = np.argmax(cosine_sims)\n",
    "        example.context = ex_context[index_max]\n",
    "        \n",
    "    # otherwise, retrieve all context passages which achieve \n",
    "    # at least AVG_COSINE_SIM similarity with the question and \n",
    "    # summarize them using the XLNet-based summarizer. Set the \n",
    "    # summary as the context for the question. \n",
    "    else: \n",
    "        context_passages = \"\"\n",
    "        for idx, elem in enumerate(min_cosine_sim_achieved): \n",
    "            if elem == 'T': \n",
    "                context_passages += ex_context[idx]\n",
    "                \n",
    "        context_passages_summary = ''.join(summarizer(context_passages, min_length = 60))\n",
    "        example.context = context_passages_summary\n",
    "\n",
    "    # generate a prediction using `qa_template_with_passages`\n",
    "    # as done before:\n",
    "    _, ex_compl = dsp.generate(qa_template_with_passages)(example, stage='qa')\n",
    "    \n",
    "    # return the generated `Completions` instance: \n",
    "    return ex_compl\n",
    "\n",
    "# system evaluation: \n",
    "few_shot_openqa_with_custom_context_and_demo_filtering_results = evaluateAnswer(\n",
    "    few_shot_openqa_with_custom_context_and_demo_filtering, tiny_dev)\n",
    "em, f1 = few_shot_openqa_with_custom_context_and_demo_filtering_results['em'], few_shot_openqa_with_custom_context_and_demo_filtering_results['f1']\n",
    "print(f'Number of exact matches :: {em} out of {len(tiny_dev)}, F1 on evaluation set: {f1:.3f}')\n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b39c60-7494-46a6-b450-42b7e9fe3aad",
   "metadata": {},
   "source": [
    "## Question 4: Bakeoff entry [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff871c1-cc38-4e2f-af38-45b3619e8329",
   "metadata": {},
   "source": [
    "For the bake-off, you simply need to be able to run your system on the file \n",
    "\n",
    "```data/openqa/cs224u-openqa-test-unlabeled.txt```\n",
    "\n",
    "The following code should download it for you if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ca87f81-556b-46eb-904f-a3df70fdacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")):\n",
    "    !mkdir -p data/openqa\n",
    "    !wget https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt -P data/openqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0024b-9af7-4e3b-930e-1e7603d4d85c",
   "metadata": {},
   "source": [
    "If the above fails, you can just download https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt and place it in `data/openqa`.\n",
    "\n",
    "This file contains only questions. The starter code below will help you structure this. It writes a file \"cs224u-openqa-bakeoff-entry.json\" to the current directory. That file should be uploaded as-is. Please do not change its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "403b0000-5bc0-4657-91e4-5a6e87f2f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_bakeoff_submission(fn):\n",
    "    \"\"\"\"\n",
    "    The argument `fn` is a DSP program with the same signature as the \n",
    "    ones we wrote above: `dsp.Example` to `dsp.Completions`.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")\n",
    "\n",
    "    # This should become a mapping from questions (str) to response\n",
    "    # dicts from your system.\n",
    "    gens = {} \n",
    "\n",
    "    with open(filename) as f:\n",
    "        questions = f.read().splitlines()\n",
    "\n",
    "    questions = [dsp.Example(question=q) for q in questions]\n",
    "\n",
    "    # `questions` is the list of `dsp.Example` instances you need to \n",
    "    # evaluate your system on. \n",
    "    #\n",
    "    # Here we loop over the questions, run the system `fn`, and\n",
    "    # store its `answer` value as the prediction:\n",
    "    for question in tqdm.tqdm(questions):\n",
    "        gens[question.question] = fn(question).answer\n",
    "        # write results to file incrementally to ensure no lost progress:\n",
    "        with open(\"cs224u-openqa-bakeoff-entry.json\", \"wt\") as f:\n",
    "            json.dump(gens, f, indent=4)\n",
    "            \n",
    "    # Quick tests we advise you to run: \n",
    "    # 1. Make sure `gens` is a dict with the questions as the keys:\n",
    "    assert all(q.question in gens for q in questions)\n",
    "    # 2. Make sure the values are dicts and have the key we will use:\n",
    "    assert all(isinstance(d, str) for d in gens.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f32a8-547e-4a2c-8283-44adf69657ed",
   "metadata": {},
   "source": [
    "Here's what it looks like to evaluate our first program, `few_shot_openqa`, on the bakeoff data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20e9ae-bb82-4dff-896f-aad7f150177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bakeoff_submission(few_shot_openqa_with_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc235578",
   "metadata": {},
   "source": [
    "And here's a function call to evaluate the original bakeoff system, ```few_shot_openqa_with_custom_context_and_demo_filtering```, on the bakeoff data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9c288a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/400 [03:26<1:48:46, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/400 [03:43<1:49:14, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 17/400 [05:05<2:05:12, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 19/400 [05:46<2:08:09, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/400 [06:04<2:03:48, 19.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 21/400 [06:23<2:01:47, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 22/400 [06:44<2:05:46, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 23/400 [07:04<2:05:02, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 24/400 [07:23<2:03:27, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 25/400 [07:44<2:05:29, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 26/400 [08:03<2:02:19, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 28/400 [08:43<2:03:04, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/400 [09:03<2:02:57, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30/400 [09:26<2:07:10, 20.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 31/400 [09:45<2:03:47, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 32/400 [10:03<2:01:11, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 33/400 [10:23<2:00:33, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 8.4 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 35/400 [11:07<2:03:37, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 36/400 [11:23<1:56:28, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 37/400 [11:48<2:06:24, 20.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 38/400 [12:03<1:54:40, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 39/400 [12:23<1:56:26, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [12:45<2:01:25, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 41/400 [13:03<1:56:53, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 43/400 [13:44<1:56:53, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 49/400 [15:48<1:52:05, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [16:04<1:45:43, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.3 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 51/400 [16:26<1:53:08, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 52/400 [16:44<1:50:09, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 53/400 [17:05<1:53:38, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 54/400 [17:23<1:50:06, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 55/400 [17:44<1:52:36, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 56/400 [18:08<1:59:40, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 57/400 [18:23<1:49:50, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 58/400 [18:48<1:59:06, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 59/400 [19:05<1:52:05, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 60/400 [19:23<1:49:47, 19.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 61/400 [19:47<1:56:58, 20.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 62/400 [20:06<1:53:35, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 63/400 [20:24<1:49:38, 19.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 64/400 [20:47<1:54:03, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 65/400 [21:03<1:47:45, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 66/400 [21:25<1:50:38, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 67/400 [21:48<1:55:34, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 68/400 [22:04<1:47:36, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 69/400 [22:24<1:49:17, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 70/400 [22:43<1:46:52, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 71/400 [23:05<1:50:52, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 72/400 [23:24<1:47:46, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 73/400 [23:44<1:48:26, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 7.0 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 77/400 [25:05<1:47:29, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 78/400 [25:25<1:46:01, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 79/400 [25:45<1:46:22, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [26:03<1:43:38, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 81/400 [26:23<1:43:47, 19.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 82/400 [26:45<1:48:13, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 83/400 [27:04<1:44:55, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 84/400 [27:23<1:43:07, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 86/400 [28:03<1:42:55, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 13.9 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 89/400 [29:06<1:40:31, 19.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 90/400 [29:23<1:36:43, 18.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 91/400 [29:43<1:37:50, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 92/400 [30:04<1:41:04, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 93/400 [30:23<1:39:02, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 94/400 [30:45<1:42:31, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 95/400 [31:04<1:41:34, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 96/400 [31:24<1:40:31, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 97/400 [31:43<1:39:06, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.5 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 98/400 [32:05<1:42:40, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 99/400 [32:23<1:38:21, 19.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [32:45<1:42:21, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 101/400 [33:03<1:37:32, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 102/400 [33:23<1:38:47, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 103/400 [33:44<1:38:51, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 104/400 [34:04<1:38:22, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 105/400 [34:24<1:39:02, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 106/400 [34:45<1:39:53, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 107/400 [35:04<1:36:52, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 109/400 [35:43<1:35:08, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 110/400 [36:03<1:34:36, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 113/400 [37:06<1:36:13, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 116/400 [38:04<1:32:27, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 117/400 [38:24<1:32:42, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 118/400 [38:44<1:32:59, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [39:23<1:32:54, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 122/400 [40:04<1:32:34, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 123/400 [40:24<1:32:14, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 125/400 [41:05<1:33:07, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 126/400 [41:26<1:33:59, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 127/400 [41:43<1:28:53, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 128/400 [42:03<1:28:42, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 132/400 [43:25<1:28:02, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 135/400 [44:25<1:27:58, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 136/400 [44:45<1:26:50, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 137/400 [45:03<1:24:35, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 138/400 [45:23<1:25:23, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 140/400 [46:04<1:24:48, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 141/400 [46:23<1:24:06, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 142/400 [46:45<1:26:51, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 143/400 [47:04<1:25:10, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 144/400 [47:24<1:25:34, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 145/400 [47:44<1:25:04, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 149/400 [49:05<1:23:37, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 152/400 [50:03<1:19:40, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 153/400 [50:24<1:20:46, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 154/400 [50:43<1:20:35, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 155/400 [51:03<1:20:32, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 156/400 [51:26<1:23:22, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 157/400 [51:44<1:20:26, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 158/400 [52:04<1:19:54, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 159/400 [52:24<1:19:39, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 161/400 [53:06<1:20:10, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 162/400 [53:24<1:18:20, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 163/400 [53:43<1:16:48, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 164/400 [54:04<1:18:12, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 166/400 [54:44<1:16:58, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 167/400 [55:04<1:16:41, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 168/400 [55:23<1:16:01, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 169/400 [55:44<1:16:40, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 170/400 [56:04<1:16:52, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 171/400 [56:24<1:16:17, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 172/400 [56:44<1:15:32, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 174/400 [57:28<1:17:19, 20.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 175/400 [57:43<1:11:11, 18.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 176/400 [58:06<1:14:55, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 177/400 [58:24<1:12:39, 19.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 179/400 [59:04<1:12:06, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 180/400 [59:25<1:12:36, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 181/400 [59:45<1:12:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 182/400 [1:00:04<1:11:07, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 183/400 [1:00:25<1:12:43, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 184/400 [1:00:44<1:11:21, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 185/400 [1:01:04<1:11:04, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 186/400 [1:01:25<1:11:38, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 187/400 [1:01:43<1:09:42, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 188/400 [1:02:03<1:09:32, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 189/400 [1:02:25<1:12:06, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 190/400 [1:02:43<1:09:10, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 192/400 [1:03:25<1:09:13, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 193/400 [1:03:45<1:09:47, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 194/400 [1:04:04<1:07:36, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 195/400 [1:04:26<1:09:23, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 196/400 [1:04:43<1:06:21, 19.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 197/400 [1:05:04<1:07:05, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 198/400 [1:05:24<1:06:44, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [1:06:03<1:05:09, 19.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 202/400 [1:06:44<1:05:03, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 7.1 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 204/400 [1:07:27<1:06:11, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 205/400 [1:07:46<1:04:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 206/400 [1:08:04<1:02:08, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 207/400 [1:08:25<1:03:21, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 208/400 [1:08:43<1:01:50, 19.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 210/400 [1:09:25<1:02:59, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 211/400 [1:09:44<1:01:41, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 212/400 [1:10:05<1:02:41, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 213/400 [1:10:26<1:03:02, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 214/400 [1:10:44<1:00:38, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 215/400 [1:11:03<1:00:01, 19.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 216/400 [1:11:23<1:00:06, 19.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 10.7 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 219/400 [1:12:24<56:47, 18.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 220/400 [1:12:45<58:11, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 221/400 [1:13:05<59:08, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 222/400 [1:13:25<58:17, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 223/400 [1:13:44<57:38, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 224/400 [1:14:03<57:12, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 225/400 [1:14:24<58:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 226/400 [1:14:43<56:57, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 227/400 [1:15:03<56:57, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 228/400 [1:15:23<56:52, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 230/400 [1:16:04<56:24, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 231/400 [1:16:23<55:17, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 232/400 [1:16:46<57:42, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 233/400 [1:17:03<54:18, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 234/400 [1:17:23<54:34, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 235/400 [1:17:44<54:32, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 236/400 [1:18:03<53:54, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 242/400 [1:20:04<50:15, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 244/400 [1:20:43<49:37, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 245/400 [1:21:05<51:21, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 246/400 [1:21:23<49:42, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 247/400 [1:21:45<51:15, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 248/400 [1:22:03<49:55, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 249/400 [1:22:23<49:42, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 251/400 [1:23:04<49:09, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 254/400 [1:24:03<46:59, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 257/400 [1:25:07<48:01, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 258/400 [1:25:24<45:25, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 260/400 [1:26:04<45:30, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 261/400 [1:26:24<45:22, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 263/400 [1:27:05<45:36, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 264/400 [1:27:24<44:26, 19.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 265/400 [1:27:44<44:44, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 266/400 [1:28:04<44:21, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 267/400 [1:28:23<43:31, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 269/400 [1:29:03<43:08, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 271/400 [1:29:44<43:07, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 272/400 [1:30:04<42:14, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 274/400 [1:30:45<41:51, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 14.5 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 279/400 [1:32:24<36:39, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 281/400 [1:33:05<38:15, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 283/400 [1:33:43<37:26, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 284/400 [1:34:03<37:41, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 286/400 [1:34:44<37:23, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 288/400 [1:35:23<36:34, 19.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 15.2 seconds after 5 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 292/400 [1:36:45<32:56, 18.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 293/400 [1:37:03<32:54, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 294/400 [1:37:23<33:25, 18.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 296/400 [1:38:03<33:14, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 297/400 [1:38:24<33:40, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 298/400 [1:38:45<34:24, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 299/400 [1:39:03<32:50, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 300/400 [1:39:24<33:25, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 301/400 [1:39:44<32:38, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 303/400 [1:40:24<31:47, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399/400 [2:12:51<00:16, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x000001643308F040> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [2:13:16<00:00, 19.99s/it]\n"
     ]
    }
   ],
   "source": [
    "create_bakeoff_submission(few_shot_openqa_with_custom_context_and_demo_filtering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
